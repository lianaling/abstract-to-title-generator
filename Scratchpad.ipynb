{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_from_disk\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import BertTokenizer, DataCollatorForSeq2Seq, EncoderDecoderConfig, EncoderDecoderModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize pretrained model for finetuning\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = EncoderDecoderModel.from_encoder_decoder_pretrained('bert-base-uncased', 'bert-base-uncased')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_from_disk('arxiv_AI_dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SOURCE_LEN = 512\n",
    "MAX_TARGET_LEN = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(example):\n",
    "    \n",
    "    model_inputs = tokenizer(example['abstract'], max_length=MAX_SOURCE_LEN, padding=False, truncation=True)\n",
    "\n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        labels = tokenizer(example['title'], max_length=MAX_SOURCE_LEN, padding=False, truncation=True)\n",
    "\n",
    "    # Replace all pad token ids in the labels by -100 to ignore padding in the loss\n",
    "    labels[\"input_ids\"] = [\n",
    "        [(l if l != tokenizer.pad_token_id else -100) for l in label] for label in labels[\"input_ids\"]\n",
    "    ]\n",
    "\n",
    "    model_inputs['labels'] = labels[\"input_ids\"]\n",
    "\n",
    "    return model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running tokenizer on dataset: 100%|██████████| 37/37 [02:34<00:00,  4.18s/ba]\n",
      "Running tokenizer on dataset: 100%|██████████| 3/3 [00:09<00:00,  3.17s/ba]\n",
      "Running tokenizer on dataset: 100%|██████████| 3/3 [00:08<00:00,  2.89s/ba]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['attention_mask', 'input_ids', 'labels', 'token_type_ids'],\n",
       "        num_rows: 36074\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['attention_mask', 'input_ids', 'labels', 'token_type_ids'],\n",
       "        num_rows: 2005\n",
       "    })\n",
       "    val: Dataset({\n",
       "        features: ['attention_mask', 'input_ids', 'labels', 'token_type_ids'],\n",
       "        num_rows: 2004\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply preprocess_data() to the whole dataset\n",
    "processed_dataset = dataset.map(\n",
    "    preprocess_data,\n",
    "    batched=True,\n",
    "    remove_columns=['abstract', 'title'],\n",
    "    desc=\"Running tokenizer on dataset\",\n",
    ")\n",
    "processed_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set return type to torch tensors\n",
    "processed_dataset.set_format(type='torch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, val_data, test_data = processed_dataset['train'], processed_dataset['val'], processed_dataset['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForSeq2Seq(\n",
    "    tokenizer,\n",
    "    model=model,\n",
    "    label_pad_token_id=-100\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_data, shuffle=True, collate_fn=data_collator, batch_size=2)\n",
    "val_loader = DataLoader(val_data, collate_fn=data_collator, batch_size=2)\n",
    "test_loader = DataLoader(test_data, collate_fn=data_collator, batch_size=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ARTICLE_TO_SUMMARIZE = \"The dominant sequence transduction models are based on complex recurrent or convolutional neural networks in an encoder-decoder configuration. The best performing models also connect the encoder and decoder through an attention mechanism. We propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely. Experiments on two machine translation tasks show these models to be superior in quality while being more parallelizable and requiring significantly less time to train. Our model achieves 28.4 BLEU on the WMT 2014 English-to-German translation task, improving over the existing best results, including ensembles by over 2 BLEU. On the WMT 2014 English-to-French translation task, our model establishes a new single-model state-of-the-art BLEU score of 41.8 after training for 3.5 days on eight GPUs, a small fraction of the training costs of the best models from the literature. We show that the Transformer generalizes well to other tasks by applying it successfully to English constituency parsing both with large and limited training data.\"\n",
    "inputs = tokenizer([ARTICLE_TO_SUMMARIZE], max_length=512, return_tensors='pt')\n",
    "\n",
    "# Generate Summary\n",
    "summary_ids = model.generate(inputs['input_ids'], num_beams=4, max_length=100, early_stopping=True)\n",
    "print([tokenizer.decode(g, skip_special_tokens=True, clean_up_tokenization_spaces=False) for g in summary_ids])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(train_loader.__iter__())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bhave\\.conda\\envs\\ai\\lib\\site-packages\\transformers\\models\\encoder_decoder\\modeling_encoder_decoder.py:490: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "output = model(**batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(10.1948, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.config.decoder_start_token_id = tokenizer.cls_token_id\n",
    "model.config.pad_token_id = tokenizer.pad_token_id\n",
    "model.config.vocab_size = model.config.decoder.vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = tokenizer(\"Hello, my dog is cute\", return_tensors=\"pt\").input_ids\n",
    "labels = tokenizer(\"Salut, mon chien est mignon\", return_tensors=\"pt\").input_ids\n",
    "outputs = model(input_ids=batch['input_ids'], labels=batch['labels'])\n",
    "loss, logits = outputs.loss, outputs.logits\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.194809913635254\n",
      "9.398115158081055\n",
      "7.756308078765869\n",
      "6.957815647125244\n",
      "5.367212772369385\n",
      "4.701416969299316\n",
      "3.9998509883880615\n",
      "3.793119192123413\n",
      "3.600857973098755\n",
      "3.40639328956604\n"
     ]
    }
   ],
   "source": [
    "for e in range(50):\n",
    "    optimizer.zero_grad()\n",
    "    output = model(**batch)\n",
    "    logits, loss = output.logits, output.loss\n",
    "    print(loss.item())\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained = EncoderDecoderModel.from_pretrained('Callidior/bert2bert-base-arxiv-titlegen')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pretrained.config.decoder == model.config.decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "transformers_version transformers_version\n",
      "('4.3.2', '4.12.3')\n"
     ]
    }
   ],
   "source": [
    "for attr1, attr2 in zip(dir(pretrained.config.decoder), dir(model.config.decoder)):\n",
    "    if not attr1.startswith('_') and not attr2.startswith('_') and eval(f\"type(pretrained.config.decoder.{attr1}) in [int, str, float]\"):\n",
    "        if eval(f\"pretrained.config.decoder.{attr1} == model.config.decoder.{attr2}\"):\n",
    "            pass\n",
    "        else:\n",
    "            print(False)\n",
    "            print(attr1, attr2)\n",
    "            print(eval(f\"pretrained.config.decoder.{attr1}, model.config.decoder.{attr2}\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = EncoderDecoderModel.from_pretrained('Callidior/bert2bert-base-arxiv-titlegen', config=model.config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model2.generate(batch['input_ids'], num_beams=4, max_length=100, early_stopping=True)\n",
    "\n",
    "for i, l in enumerate(batch['labels']):\n",
    "    print('\\nPrediction:', tokenizer.decode(output[i], skip_special_tokens=True), '\\n')\n",
    "    print('Labels:', tokenizer.decode(l.where(l != -100, torch.ones(l.shape).long()), skip_special_tokens=True), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prediction: rule discovery for obesity risk prediction ehr data mining ehr rule discovery method \n",
      "\n",
      "Labels: identifying the leading factors of significant weight gains using a new rule discovery method \n",
      "\n",
      "\n",
      "Prediction: state of ai ethics report ( june 2020 )ss on the state of ai ethics report on the state of ai ethics report ( soccer ethics report ) on the state of ai ethics report ( june 2020 on the state of ai ethics report ( soccer ethics report on the state of \n",
      "\n",
      "Labels: the state of ai ethics report ( june 2020 ) [unused0] [unused0] [unused0] [unused0] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, l in enumerate(batch['labels']):\n",
    "    print('\\nPrediction:', tokenizer.decode(output[i], skip_special_tokens=True), '\\n')\n",
    "    print('Labels:', tokenizer.decode(l.where(l != -100, torch.ones(l.shape).long()), skip_special_tokens=True), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(\n",
    "    model,\n",
    "    train_data,\n",
    "    val_data,\n",
    "    batch_size,\n",
    "    lr,\n",
    "    epochs,\n",
    "    device=None\n",
    "):  \n",
    "    if device is None:\n",
    "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    \n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=lr)\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.5)\n",
    "    # criterion = nn.CrossEntropyLoss(ignore_index=0) # ignore pad idx\n",
    "\n",
    "    n_train_steps = len(train_data) // batch_size\n",
    "\n",
    "    model.to(device)\n",
    "\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "\n",
    "    for e in range(epochs):\n",
    "\n",
    "        epoch_train_loss = []\n",
    "        epoch_val_loss = []\n",
    "\n",
    "        train_loader = DataGenerator(train_data, batch_size)\n",
    "        val_loader = DataGenerator(val_data, batch_size)\n",
    "\n",
    "        # Training\n",
    "        model.train()\n",
    "        pbar = tqdm(total=n_train_steps, desc=f\"Epoch {e+1}\")\n",
    "\n",
    "        for i, (image_inputs, caption_inputs) in enumerate(train_loader):\n",
    "\n",
    "            inputs = {\n",
    "                'pixel_values': image_inputs['pixel_values'].to(device),\n",
    "                'labels': caption_inputs['input_ids'].to(device)\n",
    "            }\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            output = model(**inputs)\n",
    "            \n",
    "            logits = output.logits\n",
    "#             logits = logits.reshape(-1, logits.shape[2])\n",
    "#             targets = caption_inputs['input_ids'].to(device).reshape(-1)\n",
    "            \n",
    "            loss = output.loss\n",
    "#             loss = criterion(logits, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            pbar.set_postfix({'Loss': loss.item()})\n",
    "            pbar.update(1)\n",
    "            epoch_train_loss.append(loss.item())\n",
    "\n",
    "        scheduler.step()\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for i, (image_inputs, caption_inputs) in enumerate(val_loader):\n",
    "\n",
    "                inputs = {\n",
    "                    'pixel_values': image_inputs['pixel_values'].to(device),\n",
    "#                     'decoder_input_ids': caption_inputs['input_ids'].to(device),\n",
    "#                     'decoder_attention_mask': caption_inputs['attention_mask'].to(device),\n",
    "                    'labels': caption_inputs['input_ids'].to(device)\n",
    "                }\n",
    "\n",
    "                output = model(**inputs)\n",
    "                logits = output.logits\n",
    "#                 logits = logits.reshape(-1, logits.shape[2])\n",
    "#                 targets = caption_inputs['input_ids'].to(device).reshape(-1)\n",
    "\n",
    "#                 loss = criterion(logits, targets)\n",
    "                loss = output.loss\n",
    "                epoch_val_loss.append(loss.item())\n",
    "\n",
    "        mean_epoch_train_loss = np.array(epoch_train_loss).mean()\n",
    "        mean_epoch_val_loss = np.array(epoch_val_loss).mean()\n",
    "\n",
    "        train_losses.append(mean_epoch_train_loss)\n",
    "        val_losses.append(mean_epoch_val_loss)\n",
    "\n",
    "        pbar.set_postfix({'Train Loss': mean_epoch_train_loss, 'Val Loss': mean_epoch_val_loss})\n",
    "\n",
    "    model.to('cpu')\n",
    "\n",
    "    return {'model': model, 'train_losses': train_losses, 'val_losses': val_losses}\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "60fbf1aecf0122793952a73a80d27bc8732eff9e143c13520ca117508929b1c7"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
